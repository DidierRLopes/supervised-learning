{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab9ec67-891b-4ecc-92ab-34f07aa505cd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Supervised Learning Steps</summary>\n",
    "    \n",
    "1. Data Collection\n",
    "   * 1.1\\. Data Sources\n",
    "   * 1.2\\. Data Collection Considerations\n",
    "2. Data Exploration and Preparation\n",
    "   * 2.1\\. Data Exploration\n",
    "   * 2.2\\. Data Preparation/Cleaning\n",
    "3. Split Data into Training and Test Sets\n",
    "   * 3.1\\. Holdout Method\n",
    "   * 3.2\\. Cross Validation\n",
    "   * 3.3\\. Data Leakage\n",
    "   * 3.4\\. Best Practices\n",
    "4. Choose a Supervised Learning Algorithm\n",
    "   * 4.1\\. Consider algorithm categories\n",
    "   * 4.2\\. Evaluate algorithm characteristics\n",
    "   * 4.3\\. Try multiple algorithms\n",
    "5. Train the Model\n",
    "   * 5.1\\. Objective Function (Loss/Cost Function)\n",
    "   * 5.2\\. Optimization Algorithms\n",
    "   * 5.3\\. Overfitting and Underfitting\n",
    "6. Evaluate Model Performance\n",
    "   * 6.1\\. Evaluate Model Performance\n",
    "   * 6.2\\. Performance Metrics for Classification Models\n",
    "   * 6.3\\. Interpreting and Reporting Model Performance\n",
    "7. Model Tuning and Selection\n",
    "   * 7.1\\. Hyperparameter Tuning\n",
    "   * 7.2\\. Ensemble Methods\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff27964-cfb8-46b0-be19-254a3cded8e0",
   "metadata": {},
   "source": [
    "# 5. Train the Model\n",
    "\n",
    "![image.png](https://pbs.twimg.com/media/D3SwgeEWAAAaSEv.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13886a88-569a-4ccb-a254-e5aa29eac62e",
   "metadata": {},
   "source": [
    "## 5.1. Objective Function (Loss/Cost Function)\n",
    "\n",
    "The objective function, also known as the loss or cost function, measures how well the model's predictions match the true labels in the training data. The goal is to minimize this function during training.\n",
    "\n",
    "The selection of a loss function is not one-size-fits-all. It requires a deep understanding of the problem, the nature of the data, the distribution of the target variable, and the specific goals of the analysis.\n",
    "\n",
    "### 5.1.1. Regression Example\n",
    "\n",
    "In regression tasks, where the goal is to predict a continuous value, the difference between the predicted and actual values is of primary concern. Common loss functions for regression include:\n",
    "\n",
    "**Mean Squared Error (MSE)**: $\\frac{1}{n} \\Sigma_{i=1}^n({y}-\\hat{y})^2$\n",
    "\n",
    "- Suitable for problems where large errors are particularly undesirable since they are squared and thus have a disproportionately large impact. The squaring operation amplifies larger errors.\n",
    "\n",
    "- Examples where MSE is preferred over MAE:\n",
    "    - **Medical diagnosis**: In medical applications, large errors in diagnosis or treatment can have severe consequences. MSE heavily penalizes large errors, making it a more appropriate metric for such critical domains.\n",
    "    - **Financial risk management**: In finance, large errors in risk estimation or portfolio optimization can lead to substantial losses. MSE's emphasis on large errors makes it a better choice for managing financial risks.\n",
    "    - **Structural engineering**: In structural design, large errors in load or stress calculations can lead to catastrophic failures. MSE's sensitivity to large errors is desirable for ensuring safety margins.\n",
    "    - **Image and signal processing**: In applications like image compression or signal denoising, large errors can significantly degrade the output quality. MSE is commonly used as it captures the perceptual impact of large errors better than MAE.\n",
    "\n",
    "**Mean Absolute Error (MAE)**: $\\frac{1}{n} \\Sigma_{i=1}^n |{y}-\\hat{y}|$\n",
    "\n",
    "- Useful when all errors, regardless of magnitude, are treated uniformly.\n",
    "\n",
    "- Examples where MAE is preferred over MSE:\n",
    "    - **Forecasting sales or revenue**: In business settings, large errors in forecasting sales or revenue may not be substantially worse than smaller errors, as long as the overall trend is captured accurately. MAE treats all errors equally, making it a suitable metric in such cases.\n",
    "    - **Measuring sensor errors**: When dealing with sensor data, large errors or outliers may be caused by temporary malfunctions or noise. MAE is more robust to such outliers and provides a better measure of the typical error.\n",
    "    - **Evaluating navigation systems**: In navigation applications, small and large errors in distance estimation may have similar consequences (e.g., missing a turn). MAE captures the average error without heavily penalizing large deviations.\n",
    "\n",
    "\n",
    "### 5.1.2. Classification Example\n",
    "\n",
    "In classification tasks, where the goal is to categorize inputs into classes, the focus is on the discrepancy between the predicted class probabilities and the actual class labels. Common loss functions for classification include:\n",
    "\n",
    "**Log Loss (Logistic Loss)**: $L(y, f(x)) = -[y * log(f(x)) + (1 - y) * log(1 - f(x))]$\n",
    "\n",
    "- Typically used for binary classification problems, where the goal is to predict the probability of an instance belonging to one of two classes. Where:\n",
    "    - y is the true binary label (0 or 1)\n",
    "    - f(x) is the predicted probability of the positive class (between 0 and 1)\n",
    "\n",
    "- Some examples include: Email spam detection (spam or not spam); Credit risk modeling (default or not default); Disease diagnosis (diseased or healthy); Fraud detection (fraudulent or legitimate transaction).\n",
    "\n",
    "**Hinge Loss**: $L(y, f(x)) = max(0, 1 - y * f(x))$\n",
    "\n",
    "- Typically used in maximum-margin classification problems, particularly with Support Vector Machines (SVMs). It is suitable for binary classification tasks where the goal is to maximize the margin between the two classes. Where:\n",
    "    - y is the true label or target value (-1 or 1)\n",
    "    - f(x) is the predicted value or decision function output\n",
    " \n",
    "- Some examples include: Text classification (e.g., sentiment analysis); Image classification (e.g., object detection); Bioinformatics (e.g., protein classification); Anomaly detection.\n",
    "\n",
    "**Cross-Entropy Loss**: $L = -\\sum_{c=1}^My_{o,c}\\log(p_{o,c})$\n",
    "\n",
    "- Generalization of Log Loss for multiclass classification problems, where instances can belong to one of several classes. Where:\n",
    "    - M is the number of classes\n",
    "    - y is a binary indicator (0 or 1) if class label c is the correct classification for observation o\n",
    "    - p is the predicted probability that observation o is of class c\n",
    "\n",
    "- Some examples include: Image classification (e.g., classifying images into multiple categories); Natural language processing (e.g., text categorization, language modeling); Speech recognition; Recommender systems (e.g., predicting user preferences among multiple items)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075589ec-d098-40fe-b3f9-f40fe0599f9a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 5.2. Optimization Algorithms\n",
    "\n",
    "To find the model parameters (weights and biases) that minimize the loss function, optimization algorithms are used. Some popular ones:\n",
    "\n",
    "- **Gradient Descent**: Updates parameters in the direction of the negative gradient of the loss function.\n",
    "- **Stochastic Gradient Descent (SGD)**: Estimates the gradient from a single example or subset of examples instead of the full dataset, allowing faster iterations.\n",
    "- **Adam Optimizer**: An extension of SGD that adapts the learning rate for each parameter, providing faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386a4ca-9333-40bf-9af2-a13e5301c374",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 5.3. Overfitting and Underfitting\n",
    "\n",
    "It's crucial to address the concepts of overfitting and underfitting when training models. Underfitting is caused by high bias (oversimplified model), while overfitting is caused by high variance (overly complex model that captures noise). The goal is to find the right balance between bias and variance by selecting an appropriate model complexity that can capture the true patterns in the data without overfitting.\n",
    "\n",
    "### 5.3.1. Overfitting (high variance and low bias)\n",
    "\n",
    "Overfitting occurs when the model learns the training data too well, including the noise, and fails to generalize to new unseen data. This leads to poor performance on the test/validation set despite high training accuracy.\n",
    "\n",
    "Variance refers to the amount that the model's predictions fluctuate when trained on different subsets of the training data. High variance indicates that the model is overly complex and sensitive to noise in the training data.\n",
    "\n",
    "Possible reasons are:\n",
    "- The model is too complex for the data (for example a very tall decision tree or a very deep or wide neural network often overfit);\n",
    "- Too many features but a small number of training examples.\n",
    "\n",
    "<u>**Methods to prevent overfitting**:</u>\n",
    "\n",
    "- **Regularization techniques**: Forces the learning algorithm to build a less complex model. In practice, that often leads to slightly higher bias but significantly reduces the variance. This problem is known in the literature as the \"bias-variance tradeoff\"\u0000. Types:\n",
    "    - **L1 (Lasso) Regularization**: Adds the sum of absolute values of weights, driving some weights to zero for sparse models. In practice this works as \"feature selection\" by deciding which features are essential for prediction and which are not.\n",
    "    \n",
    "    - **L2 (Ridge) Regularization**: Adds the sum of squared weights, keeping all weights non-zero but small.\n",
    "    \n",
    "    - For **Neural Netowrks**:\n",
    "    \n",
    "        - **Dropout**: Randomly drops units from the neural network during training to prevent co-adaptation of features.\n",
    "        \n",
    "        - **Batch Normalization**: Nrmalizes layer inputs by subtracting mean and dividing by standard deviation, enabling higher learning rates, reducing internal covariate shift, improving generalization, and faster convergence during training of deep neural networks.\n",
    "\n",
    "\n",
    "- **Cross-validation**: Splitting the data into training, validation, and test sets. The validation set is used to tune hyperparameters and monitor for overfitting during training.\n",
    "\n",
    "- **Early Stopping**: Stop training when validation error starts increasing\n",
    " \n",
    "- **Data augmentation**: Increasing the size and diversity of the training data by applying transformations like flipping, rotating, or adding noise. This helps the model generalize better.\n",
    "\n",
    "- **Reducing model complexity**: Using a simpler model with fewer parameters (linear instead of polynomial regression), a simpler kernel (linear kernel instead of RBF), or techniques like pruning to remove unnecessary connections (e.g. neural network with fewer layers/units).\n",
    "\n",
    "- **Ensemble methods**: Combining multiple models, such as bagging or boosting, to reduce variance and overfitting.\n",
    "\n",
    "- **Dimensionality reduction**: Reduce the dimensionality of the data being used, so the model has less \"noise\" that can be picked up. E.g. instead of using 4-D samples, apply PCA to reduce it to 2-D, and check whether the model generalizes better.\n",
    "\n",
    "### 5.3.2. Underfitting (high bias and low variance)\n",
    "\n",
    "Underfitting happens when the model is too simple and cannot capture the underlying patterns in the data, resulting in poor performance on both training and test sets.\n",
    "\n",
    "Bias refers to the error introduced by overly simplistic assumptions in the learning algorithm. It is the inability of the model to capture the true underlying relationship between the input features and target variable.\n",
    "\n",
    "Possible reasons are:\n",
    "- The model is too simple for the data (for example a linear model can often underfit);\n",
    "- The features you engineered are not informative enough.\n",
    "\n",
    "<u>**Methods to prevent underfitting**:</u>\n",
    "\n",
    "- **Increasing model complexity**: Using a more complex model with more parameters or layers to capture the underlying patterns in the data.\n",
    "\n",
    "- **Feature engineering**: Adding more relevant features or transforming existing ones to better represent the data.\n",
    "\n",
    "- **Removing noise**: Cleaning and preprocessing the data to remove irrelevant or noisy features.\n",
    "\n",
    "- **Increasing training time**: Training the model for more epochs or iterations to allow it to learn the patterns better.\n",
    "\n",
    "- **Reducing regularization**: Decreasing the regularization strength if it is causing underfitting by overly constraining the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2964d5-ecf1-4ca0-9f5c-5af93fa5b164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
